{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKOeTfUeVCOFaP+dHHzkcp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"3552acfa56864756b68db534cb46c33b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67e6c076256341979d77709d53a38483","IPY_MODEL_0784b505c88f419a846aaeb3f14bd765","IPY_MODEL_0910b7af84c44a8c91f6635a3646957a"],"layout":"IPY_MODEL_701b6dbae0ac4217a27890468ba7a3cb"}},"67e6c076256341979d77709d53a38483":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db23732fe7ce4bedabf3cd2479b3b487","placeholder":"​","style":"IPY_MODEL_5fc5a639596d49d6b5b114bca13d4a14","value":"100%"}},"0784b505c88f419a846aaeb3f14bd765":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_763e337ebc3f4bb2aeac691fb7adf8a7","max":102530333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5185a86800b649089bb326c85a9e9d10","value":102530333}},"0910b7af84c44a8c91f6635a3646957a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24a8b81f3d34417ead9941a254c15a5e","placeholder":"​","style":"IPY_MODEL_cdae1b9848f3437e807c928ced917731","value":" 97.8M/97.8M [00:00&lt;00:00, 124MB/s]"}},"701b6dbae0ac4217a27890468ba7a3cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db23732fe7ce4bedabf3cd2479b3b487":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc5a639596d49d6b5b114bca13d4a14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"763e337ebc3f4bb2aeac691fb7adf8a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5185a86800b649089bb326c85a9e9d10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24a8b81f3d34417ead9941a254c15a5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdae1b9848f3437e807c928ced917731":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ezaunYB2r4xb","executionInfo":{"status":"ok","timestamp":1674830247620,"user_tz":-60,"elapsed":25895,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"389f4fc5-7ad1-45fb-d64f-aa865ba83b67"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","sys.path.insert(0,'/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj')"],"metadata":{"id":"hshfXLsxsHqS","executionInfo":{"status":"ok","timestamp":1674830247622,"user_tz":-60,"elapsed":16,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lbnl34W_sAt8","executionInfo":{"status":"ok","timestamp":1674830251028,"user_tz":-60,"elapsed":3419,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"4ea1b53c-7703-4239-ce86-de6a6332d2ad"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.4.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n"]}]},{"cell_type":"code","source":["%%shell\n","\n","git clone https://github.com/pytorch/vision.git\n","cd vision\n","git checkout v0.8.2\n","\n","cp references/detection/utils.py ../\n","cp references/detection/transforms.py ../\n","cp references/detection/coco_eval.py ../\n","cp references/detection/engine.py ../\n","cp references/detection/coco_utils.py ../"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fREL3PDsJT0","executionInfo":{"status":"ok","timestamp":1674830304308,"user_tz":-60,"elapsed":53286,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"d05b3e36-4f71-48b0-a83f-d03b513d6e3a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'vision'...\n","remote: Enumerating objects: 287309, done.\u001b[K\n","remote: Counting objects: 100% (8435/8435), done.\u001b[K\n","remote: Compressing objects: 100% (526/526), done.\u001b[K\n","remote: Total 287309 (delta 7983), reused 8309 (delta 7892), pack-reused 278874\u001b[K\n","Receiving objects: 100% (287309/287309), 575.38 MiB | 41.77 MiB/s, done.\n","Resolving deltas: 100% (263085/263085), done.\n","Note: switching to 'v0.8.2'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by switching back to a branch.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -c with the switch command. Example:\n","\n","  git switch -c <new-branch-name>\n","\n","Or undo this operation with:\n","\n","  git switch -\n","\n","Turn off this advice by setting config variable advice.detachedHead to false\n","\n","HEAD is now at 2f40a483d7 [v0.8.X] .circleci: Add Python 3.9 to CI (#3063)\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torchvision.transforms as transforms\n","import torchvision\n","import torch\n","\n","from matplotlib.patches import Rectangle\n","from matplotlib.lines import Line2D\n","from PIL import Image\n","from torchvision.models.detection import FasterRCNN\n","from torch.utils.data import Dataset, DataLoader\n","from typing import Any"],"metadata":{"id":"Dm4i3uG1sM0D","executionInfo":{"status":"ok","timestamp":1674830307604,"user_tz":-60,"elapsed":3312,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["test_df = pd.read_csv('/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/test_annotations.csv')\n","test_images = '/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/test'\n","\n","test_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"aswF20uCsVOz","executionInfo":{"status":"ok","timestamp":1674830308167,"user_tz":-60,"elapsed":574,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"9d578fa5-3d7b-400d-e09e-9020f46e3ab8"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            filename  width  height  class  \\\n","0  ck0t4z1yrkmfv0794t2oqhd3f_jpeg.rf.17653d46c3ee...    640     480  smoke   \n","1  ck0ujmglz85u10a468qt0d4fc_jpeg.rf.18d02755e8c9...    640     480  smoke   \n","2  ck0uivtpc841h0a46ydgo7566_jpeg.rf.00134176dc29...    640     480  smoke   \n","3  ck0nehpd69bax0721onacbe33_jpeg.rf.02ed50fbcb97...    640     480  smoke   \n","4  ck0ow7vs07tuz08485n4yz5si_jpeg.rf.179fc0e59422...    640     480  smoke   \n","\n","   xmin  ymin  xmax  ymax  \n","0   514   209   616   285  \n","1   162   210   635   302  \n","2   308   206   392   252  \n","3   274   229   454   311  \n","4   386   218   607   285  "],"text/html":["\n","  <div id=\"df-c5902e5d-3c48-43ca-b767-756bc9fcd4ba\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>class</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ck0t4z1yrkmfv0794t2oqhd3f_jpeg.rf.17653d46c3ee...</td>\n","      <td>640</td>\n","      <td>480</td>\n","      <td>smoke</td>\n","      <td>514</td>\n","      <td>209</td>\n","      <td>616</td>\n","      <td>285</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ck0ujmglz85u10a468qt0d4fc_jpeg.rf.18d02755e8c9...</td>\n","      <td>640</td>\n","      <td>480</td>\n","      <td>smoke</td>\n","      <td>162</td>\n","      <td>210</td>\n","      <td>635</td>\n","      <td>302</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ck0uivtpc841h0a46ydgo7566_jpeg.rf.00134176dc29...</td>\n","      <td>640</td>\n","      <td>480</td>\n","      <td>smoke</td>\n","      <td>308</td>\n","      <td>206</td>\n","      <td>392</td>\n","      <td>252</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ck0nehpd69bax0721onacbe33_jpeg.rf.02ed50fbcb97...</td>\n","      <td>640</td>\n","      <td>480</td>\n","      <td>smoke</td>\n","      <td>274</td>\n","      <td>229</td>\n","      <td>454</td>\n","      <td>311</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ck0ow7vs07tuz08485n4yz5si_jpeg.rf.179fc0e59422...</td>\n","      <td>640</td>\n","      <td>480</td>\n","      <td>smoke</td>\n","      <td>386</td>\n","      <td>218</td>\n","      <td>607</td>\n","      <td>285</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5902e5d-3c48-43ca-b767-756bc9fcd4ba')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c5902e5d-3c48-43ca-b767-756bc9fcd4ba button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c5902e5d-3c48-43ca-b767-756bc9fcd4ba');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["LABELS = test_df['class'].unique()\n","NUM_OF_CLASSES = len(LABELS)+1\n","SAVE_PATH = '/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/models/'\n","MODEL_NAME = 'model_include_fire.pt'\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","TRANSFORM = transforms.Compose([transforms.ToTensor()])\n","IMG_PATH = '../data/new-data/datasets/full/fire/fire-2065.jpg'"],"metadata":{"id":"NexnR_90sbB9","executionInfo":{"status":"ok","timestamp":1674830308567,"user_tz":-60,"elapsed":26,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["COLORS = ['#d90166', '#8f00f1', '#d0ff14', '#eb5030', '#ff000d', '#66ff00',\n","          '#0203e2', '#04d9ff', '#ff00ff', '#fffd01', '#e56024', '#dfff4f',\n","          '#ff3503', '#6600ff', '#f7b718', '#fe0002', '#45cea2', '#ff85ff',\n","          '#1974d2', '#fe6700']"],"metadata":{"id":"vhWiNYYxs91k","executionInfo":{"status":"ok","timestamp":1674830308569,"user_tz":-60,"elapsed":25,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class LabelMap:\n","    def __init__(self, labels: list) -> None:\n","        self._map = {c: i+1 for i, c in enumerate(labels)}\n","        self.reversed_map = {i: c for i, c in enumerate(labels)}\n","\n","    def fit(self, df: pd.DataFrame, col: str) -> pd.DataFrame:\n","        df[col] = df[col].map(self._map)\n","        return df\n","\n","\n","class WildfireDataset(Dataset):\n","    def __init__(self, df: pd.DataFrame, img_path: str, labels: list, transforms: Any = None, **kwargs) -> None:\n","        super().__init__(**kwargs)\n","        self.df = df\n","        self.img_path = img_path\n","        self.labels = labels\n","        self.images = self.df['filename'].unique()\n","        self.transforms = transforms\n","\n","    def __len__(self) -> int:\n","        return len(self.images)\n","\n","    def __getitem__(self, i: int) -> tuple:\n","        img_file = os.path.join(self.img_path, self.images[i])\n","\n","        img = Image.open(img_file)\n","        #img = img.astype(np.float32)\n","        #img = img/255.0\n","\n","        img_data = self.df.loc[self.df['filename'] == self.images[i]]\n","\n","        xmins = img_data['xmin'].values\n","        ymins = img_data['ymin'].values\n","        xmaxs = img_data['xmax'].values\n","        ymaxs = img_data['ymax'].values\n","\n","        boxes = torch.as_tensor(np.stack([xmins, ymins, xmaxs, ymaxs], axis=1), dtype=torch.float32)\n","        labels = torch.as_tensor(img_data['class'].values, dtype=torch.int64)\n","        _id = torch.tensor([i])\n","\n","        areas = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0])\n","        areas = torch.as_tensor(areas, dtype=torch.float32)\n","\n","        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n","\n","        target = dict()\n","        target['boxes'] = boxes\n","        target['labels'] = labels\n","        target['image_id'] = _id\n","        target['area'] = areas\n","        target['iscrowd'] = iscrowd\n","\n","        if self.transforms:\n","            img = self.transforms(img)\n","            #img = transformed['image']\n","            #target['boxes'] = torch.as_tensor(transformed['bboxes'], dtype=torch.float32)\n","    \n","        return torch.as_tensor(img, dtype=torch.float32), target\n","\n","    def get_h_w(self, image: str) -> tuple:\n","        \"\"\"Get height and width of image\"\"\"\n","        img_data = self.df.loc[self.df['filename'] == image]\n","        return img_data['width'].values[0], img_data['height'].values[0]"],"metadata":{"id":"dyR7jCAvtj9X","executionInfo":{"status":"ok","timestamp":1674830308571,"user_tz":-60,"elapsed":25,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def encode_label(df: pd.DataFrame, col: str, map_dict: dict) -> pd.DataFrame:\n","    df[col] = df[col].map(map_dict)\n","    return df\n","\n","def collate_fn(batch: tuple) -> tuple:\n","    return tuple(zip(*batch))\n","\n","def load_model(model_path: str) -> FasterRCNN:\n","    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n","        pretrained=False,\n","        num_classes=NUM_OF_CLASSES\n","    )\n","    IN_FEATURES = model.roi_heads.box_predictor.cls_score.in_features\n","\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","\n","    return model\n","\n","def predict(model, img: Image) -> tuple:\n","    pred_img = img.view(1, 3, img.shape[1], img.shape[2])\n","\n","    preds = model(pred_img)\n","    outputs = [{k: v.to(torch.device('cpu')) for k, v in target.items()} for target in preds]\n","\n","    boxes = outputs[0]['boxes'].data.cpu().numpy().astype(np.int32)\n","    scores = outputs[0]['scores'].data.cpu().numpy()\n","    labels = outputs[0]['labels'].data.cpu().numpy().astype(np.int32)\n","    \n","    return boxes, scores, labels\n","\n","def plot_prediction(img_path: str, predictions: tuple) -> None:\n","    patches = []\n","\n","    img = Image.open(img_path)\n","    _, ax = plt.subplots(figsize=(13,7))\n","    plt.imshow(img)\n","\n","    box_counter = 0\n","    for box, score, label in zip(predictions[0], predictions[1], predictions[2]):\n","        box_counter += 1\n","        score *= 100\n","        label = f'{str(LABELS[label-1])} : {score: .2f}%'\n","\n","        x_min = int(box[0])\n","        y_min = int(box[1])\n","        x_max = int(box[2])\n","        y_max = int(box[3])\n","\n","        plt.gca().add_patch(Rectangle(\n","            (x_min, y_min),\n","            x_max - x_min,\n","            y_max - y_min,\n","            edgecolor=COLORS[box_counter],\n","            facecolor=None,\n","            fill=False,\n","            lw=1\n","        ))\n","\n","        patch = Line2D(\n","            [0], [0],\n","            marker='o',\n","            color='w',\n","            markerfacecolor=COLORS[box_counter],\n","            label=label\n","        )\n","        patches.append(patch)\n","    \n","    box = ax.get_position()\n","    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n","    ax.legend(\n","        bbox_to_anchor=(1.05, 1),\n","        loc='upper left',\n","        borderaxespad=0.,\n","        handles=patches\n","    )\n","\n","    plt.show()"],"metadata":{"id":"iBspwn7BsoHy","executionInfo":{"status":"ok","timestamp":1674830308574,"user_tz":-60,"elapsed":26,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model = load_model(SAVE_PATH + MODEL_NAME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["3552acfa56864756b68db534cb46c33b","67e6c076256341979d77709d53a38483","0784b505c88f419a846aaeb3f14bd765","0910b7af84c44a8c91f6635a3646957a","701b6dbae0ac4217a27890468ba7a3cb","db23732fe7ce4bedabf3cd2479b3b487","5fc5a639596d49d6b5b114bca13d4a14","763e337ebc3f4bb2aeac691fb7adf8a7","5185a86800b649089bb326c85a9e9d10","24a8b81f3d34417ead9941a254c15a5e","cdae1b9848f3437e807c928ced917731"]},"id":"wkgv5w87uGqd","executionInfo":{"status":"ok","timestamp":1674830322669,"user_tz":-60,"elapsed":14119,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"4cc53338-0649-47c1-fbdb-28e802e93e99"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3552acfa56864756b68db534cb46c33b"}},"metadata":{}}]},{"cell_type":"code","source":["label_map = LabelMap(LABELS)\n","test_df = encode_label(test_df, 'class', label_map._map)"],"metadata":{"id":"5OIp7dMnuQdT","executionInfo":{"status":"ok","timestamp":1674830322671,"user_tz":-60,"elapsed":35,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["test_dataset = WildfireDataset(test_df, test_images, LABELS, TRANSFORM)\n","\n","# Is DataLoader necessary?\n","test_dataloader = DataLoader(\n","    test_dataset,\n","    batch_size=4,\n","    shuffle=True,\n","    num_workers=2,\n","    collate_fn=collate_fn\n",")"],"metadata":{"id":"u_sd3hMGuW0u","executionInfo":{"status":"ok","timestamp":1674830322675,"user_tz":-60,"elapsed":34,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["images, targets = next(iter(test_dataset))\n","targets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1-BYbEpuefi","executionInfo":{"status":"ok","timestamp":1674830322678,"user_tz":-60,"elapsed":34,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"48fc3bdd-e1dc-4fb6-e566-a11e26db4beb"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'boxes': tensor([[514., 209., 616., 285.]]),\n"," 'labels': tensor([1]),\n"," 'image_id': tensor([0]),\n"," 'area': tensor([7752.]),\n"," 'iscrowd': tensor([0])}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["MAP_targets, MAP_preds = list(), list()\n","\n","for image, target in test_dataset:\n","    #pred_img = TRANSFORM(image)\n","    prediction = predict(model, image)\n","    MAP_preds.append(dict(\n","        boxes=torch.tensor(prediction[0]),\n","        scores=torch.tensor(prediction[1]),\n","        labels=torch.tensor(prediction[2])\n","    ))\n","    MAP_targets.append(dict(\n","        boxes=target['boxes'],\n","        labels=target['labels']\n","    ))\n","\n","MAP_preds[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-uEWDamxqmb","executionInfo":{"status":"ok","timestamp":1674830932722,"user_tz":-60,"elapsed":610073,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"a8875f43-b654-4a4a-8f53-6969455c341d"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'boxes': tensor([[302, 204, 412, 252]], dtype=torch.int32),\n"," 'scores': tensor([0.9433]),\n"," 'labels': tensor([1], dtype=torch.int32)}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YM2Q1Xj7Lh8r","executionInfo":{"status":"ok","timestamp":1674830936573,"user_tz":-60,"elapsed":3868,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"68ee6cbe-78b4-4e36-b301-a2ad89aa0000"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.0\n"]}]},{"cell_type":"code","source":["from torchmetrics.detection.mean_ap import MeanAveragePrecision\n","\n","metric = MeanAveragePrecision()\n","metric.update(MAP_preds, MAP_targets)"],"metadata":{"id":"jeS7HPFfOHVO","executionInfo":{"status":"ok","timestamp":1674830936575,"user_tz":-60,"elapsed":17,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["metric.compute()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXhzQzIpSqPV","executionInfo":{"status":"ok","timestamp":1674830937834,"user_tz":-60,"elapsed":1273,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"8bea3796-4f88-447d-9851-7d9a5467ddcf"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'map': tensor(0.3073),\n"," 'map_50': tensor(0.6371),\n"," 'map_75': tensor(0.2525),\n"," 'map_small': tensor(0.2783),\n"," 'map_medium': tensor(0.2809),\n"," 'map_large': tensor(0.3584),\n"," 'mar_1': tensor(0.3083),\n"," 'mar_10': tensor(0.4550),\n"," 'mar_100': tensor(0.4749),\n"," 'mar_small': tensor(0.3556),\n"," 'mar_medium': tensor(0.4582),\n"," 'mar_large': tensor(0.5176),\n"," 'map_per_class': tensor(-1.),\n"," 'mar_100_per_class': tensor(-1.)}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["ACC_targets, ACC_preds = list(), list()\n","for i in range(len(MAP_preds)):\n","    ACC_preds.append([int(j) for j in MAP_preds[i]['labels'][:len(MAP_targets[i]['labels'])]])\n","    ACC_targets.append([int(j) for j in MAP_targets[i]['labels']])\n"],"metadata":{"id":"XU6RvYdpSsmI","executionInfo":{"status":"ok","timestamp":1674832456777,"user_tz":-60,"elapsed":5,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["ACC_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-QgrHyTyApM","executionInfo":{"status":"ok","timestamp":1674832461291,"user_tz":-60,"elapsed":293,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"c3cc66e5-8867-4803-c36f-6b66f4e89982"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [1],\n"," [2, 2],\n"," [2, 2, 2, 2, 2],\n"," [1, 1, 1, 1, 1, 1],\n"," [2, 2],\n"," [2, 2, 2, 2],\n"," [2],\n"," [2, 2, 2],\n"," [2],\n"," [2, 2, 2],\n"," [2, 1, 2],\n"," [2, 2, 2, 2],\n"," [2, 2],\n"," [2, 2, 2],\n"," [2, 2, 2],\n"," [2, 2],\n"," [2, 2],\n"," [2, 2, 2, 2, 2, 2],\n"," [2],\n"," [2, 1, 1],\n"," [2],\n"," [2],\n"," [1, 1, 1, 1],\n"," [2, 2, 2, 2, 1],\n"," [2, 1, 2],\n"," [2, 2],\n"," [2, 2, 2],\n"," [2, 2, 2],\n"," [2, 2, 2, 2, 1, 1],\n"," [2, 2],\n"," [1, 2, 2],\n"," [2],\n"," [2, 2, 2, 2],\n"," [2, 1],\n"," [2, 2],\n"," [1, 1, 2, 1]]"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["from torchmetrics.functional.classification import accuracy\n","\n","accuracy(ACC_preds, ACC_targets, task='multiclass', num_classes=NUM_OF_CLASSES)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352},"id":"FvpS2NfAWhPe","executionInfo":{"status":"error","timestamp":1674832466430,"user_tz":-60,"elapsed":272,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"38212ed4-5bdf-4c09-8de7-abfed8380449"},"execution_count":29,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-9d1b0ca2fbe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFMAT_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFMAT_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_OF_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchmetrics/functional/classification/accuracy.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(preds, target, task, threshold, num_classes, num_labels, average, multidim_average, top_k, ignore_index, validate_args)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         return multiclass_accuracy(\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultidim_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchmetrics/functional/classification/accuracy.py\u001b[0m in \u001b[0;36mmulticlass_accuracy\u001b[0;34m(preds, target, num_classes, average, top_k, multidim_average, ignore_index, validate_args)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0m_multiclass_stat_scores_arg_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultidim_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0m_multiclass_stat_scores_tensor_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultidim_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multiclass_stat_scores_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     tp, fp, tn, fn = _multiclass_stat_scores_update(\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchmetrics/functional/classification/stat_scores.py\u001b[0m in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfloating\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mall\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0malso\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \"\"\"\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If `preds` have one dimension more than `target`, `preds` should be a float tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ndim'"]}]},{"cell_type":"code","source":["import pickle\n","\n","with open('/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/map_pred.pkl', 'wb') as f:\n","    pickle.dump(MAP_preds, f)\n","\n","with open('/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/map_traget.pkl', 'wb') as f:\n","    pickle.dump(MAP_targets, f)"],"metadata":{"id":"EGrO_GlyW5fg","executionInfo":{"status":"ok","timestamp":1674831023213,"user_tz":-60,"elapsed":287,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/map_pred.pkl', 'rb') as f:\n","    test_list = pickle.load(f)\n","test_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1kfjf4Grqwc","executionInfo":{"status":"ok","timestamp":1674831025141,"user_tz":-60,"elapsed":13,"user":{"displayName":"Andreas Eliasson","userId":"14675535218151679092"}},"outputId":"7d30c1db-6a6d-49ff-93b5-0bf5819225fb"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'boxes': tensor([[521, 211, 618, 286]], dtype=torch.int32),\n","  'scores': tensor([0.9930]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[169, 240, 488, 292],\n","          [164, 251, 392, 288],\n","          [164, 253, 305, 283],\n","          [210, 234, 623, 303],\n","          [161, 255, 247, 280],\n","          [159, 206, 535, 290]], dtype=torch.int32),\n","  'scores': tensor([0.8945, 0.5829, 0.5777, 0.5639, 0.0923, 0.0811]),\n","  'labels': tensor([1, 1, 1, 1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[302, 204, 412, 252]], dtype=torch.int32),\n","  'scores': tensor([0.9433]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[266, 231, 424, 311]], dtype=torch.int32),\n","  'scores': tensor([0.9911]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[441, 218, 608, 289],\n","          [523, 242, 614, 289]], dtype=torch.int32),\n","  'scores': tensor([0.9896, 0.1347]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[126, 208, 175, 283]], dtype=torch.int32),\n","  'scores': tensor([0.9880]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[314, 157, 568, 259]], dtype=torch.int32),\n","  'scores': tensor([0.9909]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[430, 198, 545, 241]], dtype=torch.int32),\n","  'scores': tensor([0.9917]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[211, 171, 251, 236]], dtype=torch.int32),\n","  'scores': tensor([0.9908]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[308,  88, 541, 262]], dtype=torch.int32),\n","  'scores': tensor([0.9931]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[ 79, 229, 286, 289],\n","          [174, 240, 282, 290]], dtype=torch.int32),\n","  'scores': tensor([0.9930, 0.1077]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[120, 202, 193, 317]], dtype=torch.int32),\n","  'scores': tensor([0.9944]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[303,  72, 522, 262]], dtype=torch.int32),\n","  'scores': tensor([0.9961]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[453, 227, 554, 251],\n","          [441, 220, 606, 255]], dtype=torch.int32),\n","  'scores': tensor([0.9824, 0.0587]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[165, 253, 211, 279],\n","          [145, 246, 223, 278]], dtype=torch.int32),\n","  'scores': tensor([0.9870, 0.1012]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[183, 166, 420, 312]], dtype=torch.int32),\n","  'scores': tensor([0.9915]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[186, 235, 525, 294],\n","          [166, 243, 402, 284],\n","          [163, 252, 308, 281],\n","          [355, 238, 585, 302],\n","          [155, 224, 568, 321]], dtype=torch.int32),\n","  'scores': tensor([0.8660, 0.5890, 0.2539, 0.0866, 0.0545]),\n","  'labels': tensor([1, 1, 1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[182, 263, 224, 289],\n","          [174, 256, 241, 290]], dtype=torch.int32),\n","  'scores': tensor([0.9774, 0.1509]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[499, 250, 634, 290]], dtype=torch.int32),\n","  'scores': tensor([0.9892]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[184, 204, 212, 226],\n","          [162, 200, 211, 225]], dtype=torch.int32),\n","  'scores': tensor([0.9905, 0.0821]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[173, 172, 421, 316]], dtype=torch.int32),\n","  'scores': tensor([0.9930]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[271, 208, 308, 240],\n","          [260, 206, 330, 240]], dtype=torch.int32),\n","  'scores': tensor([0.9876, 0.0563]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[449, 227, 561, 251],\n","          [468, 235, 545, 248]], dtype=torch.int32),\n","  'scores': tensor([0.8829, 0.0830]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[312, 148, 472, 258]], dtype=torch.int32),\n","  'scores': tensor([0.9964]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[232, 201, 308, 240]], dtype=torch.int32),\n","  'scores': tensor([0.9969]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[  4, 254, 154, 334],\n","          [  0, 162, 153, 330]], dtype=torch.int32),\n","  'scores': tensor([0.9916, 0.0943]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[336, 261, 521, 317]], dtype=torch.int32),\n","  'scores': tensor([0.9909]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[499, 251, 627, 291]], dtype=torch.int32),\n","  'scores': tensor([0.9876]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[434, 195, 544, 241]], dtype=torch.int32),\n","  'scores': tensor([0.9934]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[195, 213, 214, 233],\n","          [185, 209, 218, 232],\n","          [145, 205, 216, 232]], dtype=torch.int32),\n","  'scores': tensor([0.8406, 0.4246, 0.1290]),\n","  'labels': tensor([1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[264, 206, 308, 240]], dtype=torch.int32),\n","  'scores': tensor([0.9909]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[309, 221, 376, 251],\n","          [274, 212, 427, 253]], dtype=torch.int32),\n","  'scores': tensor([0.9046, 0.5609]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[454, 194, 538, 243]], dtype=torch.int32),\n","  'scores': tensor([0.9946]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[  1,  50, 154, 336],\n","          [  0,  40, 157, 198],\n","          [  4,  41, 304, 332]], dtype=torch.int32),\n","  'scores': tensor([0.9977, 0.0990, 0.0588]),\n","  'labels': tensor([1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[ 92, 235, 145, 265]], dtype=torch.int32),\n","  'scores': tensor([0.5641]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[308,  80, 521, 264]], dtype=torch.int32),\n","  'scores': tensor([0.9954]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[255, 203, 310, 239]], dtype=torch.int32),\n","  'scores': tensor([0.9955]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[120, 213, 188, 314]], dtype=torch.int32),\n","  'scores': tensor([0.9946]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[174, 238, 495, 293],\n","          [165, 251, 305, 281],\n","          [330, 237, 494, 297],\n","          [162, 241, 380, 282],\n","          [160, 256, 249, 280]], dtype=torch.int32),\n","  'scores': tensor([0.9452, 0.5542, 0.3066, 0.2474, 0.0908]),\n","  'labels': tensor([1, 1, 1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[303, 263, 523, 318]], dtype=torch.int32),\n","  'scores': tensor([0.9890]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[181, 204, 213, 224],\n","          [154, 201, 210, 224]], dtype=torch.int32),\n","  'scores': tensor([0.9900, 0.0883]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[121, 181, 172, 279]], dtype=torch.int32),\n","  'scores': tensor([0.9869]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[409, 192, 534, 243]], dtype=torch.int32),\n","  'scores': tensor([0.9893]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[442, 227, 566, 251],\n","          [467, 232, 547, 250]], dtype=torch.int32),\n","  'scores': tensor([0.9812, 0.0659]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[497, 251, 632, 290],\n","          [499, 257, 576, 291]], dtype=torch.int32),\n","  'scores': tensor([0.9871, 0.0792]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[491, 213, 548, 252]], dtype=torch.int32),\n","  'scores': tensor([0.9873]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[187, 234, 537, 293],\n","          [172, 242, 422, 287],\n","          [291, 242, 594, 302],\n","          [158, 250, 336, 283],\n","          [343, 236, 494, 299],\n","          [148, 227, 601, 321]], dtype=torch.int32),\n","  'scores': tensor([0.8817, 0.6101, 0.2011, 0.1359, 0.0828, 0.0526]),\n","  'labels': tensor([1, 1, 1, 1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[305,  58, 511, 264]], dtype=torch.int32),\n","  'scores': tensor([0.9944]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[448, 227, 555, 251],\n","          [443, 234, 469, 251],\n","          [463, 234, 539, 248]], dtype=torch.int32),\n","  'scores': tensor([0.9384, 0.2510, 0.0970]),\n","  'labels': tensor([1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[327, 221, 413, 251]], dtype=torch.int32),\n","  'scores': tensor([0.9920]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[197, 205, 217, 227]], dtype=torch.int32),\n","  'scores': tensor([0.9850]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[  1,  48, 166, 321]], dtype=torch.int32),\n","  'scores': tensor([0.9964]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[257, 226, 424, 311]], dtype=torch.int32),\n","  'scores': tensor([0.9914]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[185, 238, 236, 291],\n","          [138, 231, 239, 292]], dtype=torch.int32),\n","  'scores': tensor([0.9965, 0.3307]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[188, 236, 523, 296],\n","          [164, 247, 386, 285],\n","          [312, 245, 563, 303],\n","          [163, 254, 282, 280],\n","          [165, 256, 225, 279]], dtype=torch.int32),\n","  'scores': tensor([0.8486, 0.7489, 0.4086, 0.3476, 0.0792]),\n","  'labels': tensor([1, 1, 1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[186, 203, 212, 225],\n","          [154, 201, 212, 224]], dtype=torch.int32),\n","  'scores': tensor([0.9888, 0.0794]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[434, 220, 613, 290],\n","          [543, 253, 615, 288],\n","          [497, 238, 616, 290]], dtype=torch.int32),\n","  'scores': tensor([0.9592, 0.6740, 0.2824]),\n","  'labels': tensor([1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[499, 246, 633, 291]], dtype=torch.int32),\n","  'scores': tensor([0.9921]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[300, 263, 518, 318],\n","          [383, 272, 528, 318]], dtype=torch.int32),\n","  'scores': tensor([0.9840, 0.0952]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[ 86, 231, 277, 290],\n","          [ 76, 197, 302, 285]], dtype=torch.int32),\n","  'scores': tensor([0.9947, 0.0523]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[485, 213, 613, 283],\n","          [557, 215, 615, 286]], dtype=torch.int32),\n","  'scores': tensor([0.9924, 0.0583]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[349, 245, 394, 281],\n","          [319, 241, 399, 285],\n","          [369, 246, 392, 278]], dtype=torch.int32),\n","  'scores': tensor([0.8282, 0.1079, 0.0944]),\n","  'labels': tensor([1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[284, 215, 306, 238],\n","          [261, 213, 306, 238],\n","          [284, 212, 322, 240]], dtype=torch.int32),\n","  'scores': tensor([0.9853, 0.2423, 0.0682]),\n","  'labels': tensor([1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[  3,  56, 161, 336],\n","          [ 26,  12, 287, 318]], dtype=torch.int32),\n","  'scores': tensor([0.9933, 0.2386]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[167, 203, 211, 225],\n","          [138, 200, 213, 228],\n","          [172, 205, 196, 223]], dtype=torch.int32),\n","  'scores': tensor([0.9638, 0.1445, 0.0803]),\n","  'labels': tensor([1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[299, 265, 522, 319]], dtype=torch.int32),\n","  'scores': tensor([0.9871]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[112, 178, 190, 317],\n","          [115, 172, 268, 318]], dtype=torch.int32),\n","  'scores': tensor([0.9948, 0.1835]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[  1, 174, 158, 322]], dtype=torch.int32),\n","  'scores': tensor([0.9897]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[172, 204, 210, 223],\n","          [145, 202, 210, 224]], dtype=torch.int32),\n","  'scores': tensor([0.9684, 0.6884]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[390, 223, 427, 247],\n","          [372, 218, 443, 248]], dtype=torch.int32),\n","  'scores': tensor([0.9703, 0.1033]),\n","  'labels': tensor([1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[327, 207, 442, 250]], dtype=torch.int32),\n","  'scores': tensor([0.9899]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[166, 254, 258, 279],\n","          [166, 256, 210, 279],\n","          [158, 243, 311, 279]], dtype=torch.int32),\n","  'scores': tensor([0.9785, 0.7912, 0.0686]),\n","  'labels': tensor([1, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[500, 247, 633, 289]], dtype=torch.int32),\n","  'scores': tensor([0.9926]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[494, 194, 590, 249]], dtype=torch.int32),\n","  'scores': tensor([0.9868]),\n","  'labels': tensor([1], dtype=torch.int32)},\n"," {'boxes': tensor([[193, 160, 510, 438],\n","          [208, 317, 466, 439],\n","          [  0,   1, 444, 214],\n","          [257, 246, 534, 425],\n","          [153, 141, 413, 340],\n","          [193, 366, 216, 433],\n","          [ 15,  33, 519, 326],\n","          [381, 246, 545, 378],\n","          [477, 283, 545, 362],\n","          [205, 457, 227, 479],\n","          [  1,   3, 256, 269],\n","          [135, 131, 309, 291],\n","          [192, 366, 225, 465],\n","          [338,  15, 629, 305],\n","          [250, 337, 420, 428],\n","          [202, 330, 371, 465],\n","          [ 87, 106, 468, 392],\n","          [  2,  12, 148, 339],\n","          [166,  81, 592, 411],\n","          [243, 187, 444, 378],\n","          [162, 136, 255, 275],\n","          [259, 346, 349, 447]], dtype=torch.int32),\n","  'scores': tensor([0.9717, 0.7019, 0.6394, 0.6158, 0.6014, 0.4201, 0.3913, 0.2780, 0.2707,\n","          0.2556, 0.2532, 0.1895, 0.1868, 0.1803, 0.1497, 0.1342, 0.1179, 0.1122,\n","          0.1029, 0.0812, 0.0535, 0.0533]),\n","  'labels': tensor([2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[340, 235, 503, 424],\n","          [602, 350, 640, 434],\n","          [  2, 266, 297, 443],\n","          [ 75, 311, 175, 429],\n","          [ 52, 246, 199, 440],\n","          [411, 248, 500, 421],\n","          [174, 289, 322, 425],\n","          [433, 322, 495, 413],\n","          [  0, 335, 164, 453],\n","          [  0,   8, 623, 332],\n","          [436, 340, 640, 427],\n","          [101, 235, 524, 429],\n","          [  0, 360,  93, 453],\n","          [542, 346, 640, 435],\n","          [235, 294, 322, 405],\n","          [334, 289, 449, 406],\n","          [  9,  36, 371, 389],\n","          [556, 276, 577, 362],\n","          [293, 283, 614, 432],\n","          [561, 325, 577, 349],\n","          [ 82, 303, 295, 426],\n","          [  0,   7, 204, 346],\n","          [196, 312, 277, 426],\n","          [  0, 185, 426, 415],\n","          [530, 342, 585, 428],\n","          [421, 288, 568, 422],\n","          [542, 281, 578, 430],\n","          [430, 341, 545, 411],\n","          [ 61, 256, 102, 303]], dtype=torch.int32),\n","  'scores': tensor([0.9858, 0.9615, 0.9446, 0.8895, 0.8747, 0.6743, 0.6739, 0.6376, 0.6238,\n","          0.4707, 0.4072, 0.3943, 0.3654, 0.3630, 0.3192, 0.2493, 0.2173, 0.1823,\n","          0.1676, 0.1495, 0.1203, 0.0987, 0.0985, 0.0968, 0.0889, 0.0703, 0.0575,\n","          0.0530, 0.0518]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2,\n","          2, 2, 2, 2, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[  0, 159, 118, 445],\n","          [147, 276, 268, 480],\n","          [302, 298, 615, 474],\n","          [248,   0, 621, 208],\n","          [229,   0, 461, 182],\n","          [  2,   0, 129, 155],\n","          [146, 245, 372, 480],\n","          [129,  20, 640, 433],\n","          [375,   0, 630, 329],\n","          [  1,  23, 170, 452],\n","          [313, 294, 442, 476],\n","          [556, 388, 609, 433],\n","          [324, 295, 357, 327],\n","          [  2, 138, 296, 467],\n","          [154, 202, 640, 480],\n","          [216, 261, 356, 341],\n","          [443, 300, 540, 393],\n","          [  0,   0, 124, 320],\n","          [516,   4, 635, 449],\n","          [372, 306, 613, 465],\n","          [ 16,   0, 513, 213],\n","          [482, 318, 525, 383],\n","          [  1, 222,  71, 470],\n","          [  0, 148, 557, 418],\n","          [419,   0, 619, 116],\n","          [427, 232, 634, 468],\n","          [383,   0, 551, 247],\n","          [234, 252, 551, 429],\n","          [538, 370, 616, 438],\n","          [253,  52, 393, 173]], dtype=torch.int32),\n","  'scores': tensor([0.9822, 0.9797, 0.9537, 0.8116, 0.6153, 0.5976, 0.5280, 0.4889, 0.4657,\n","          0.4413, 0.4413, 0.3957, 0.3491, 0.3052, 0.2663, 0.1650, 0.1577, 0.1467,\n","          0.1336, 0.1313, 0.1183, 0.1055, 0.1030, 0.0875, 0.0754, 0.0719, 0.0692,\n","          0.0562, 0.0524, 0.0503]),\n","  'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1,\n","          1, 1, 1, 1, 2, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[484, 400, 589, 460],\n","          [197, 346, 367, 421],\n","          [139, 105, 328, 337],\n","          [147, 232, 235, 349],\n","          [139,   9, 609, 336],\n","          [  9,   0, 183, 184],\n","          [ 37,   0, 457, 205],\n","          [118,  42, 368, 325],\n","          [361,  23, 635, 409],\n","          [153, 288, 216, 343],\n","          [151, 161, 274, 358],\n","          [288, 340, 365, 415],\n","          [168, 317, 340, 433],\n","          [150, 209, 359, 416],\n","          [195, 363, 311, 428],\n","          [133, 213, 501, 348],\n","          [195, 370, 262, 425],\n","          [317, 216, 506, 278],\n","          [312, 205, 580, 320],\n","          [495, 405, 554, 453],\n","          [473, 100, 636, 454],\n","          [296,  45, 522, 288],\n","          [141,  59, 247, 352]], dtype=torch.int32),\n","  'scores': tensor([0.9754, 0.9574, 0.8726, 0.8700, 0.6920, 0.6896, 0.5619, 0.4564, 0.2906,\n","          0.2361, 0.1476, 0.1448, 0.0984, 0.0981, 0.0815, 0.0803, 0.0767, 0.0685,\n","          0.0674, 0.0598, 0.0581, 0.0580, 0.0527]),\n","  'labels': tensor([2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[ 96, 343, 220, 478],\n","          [568, 209, 638, 334],\n","          [411, 248, 519, 325],\n","          [349, 246, 553, 385],\n","          [380, 231, 618, 344],\n","          [150, 327, 217, 472],\n","          [346, 289, 498, 389],\n","          [260, 381, 313, 412],\n","          [ 19,   9, 593, 300],\n","          [346, 336, 476, 387],\n","          [ 13,   7, 346, 383],\n","          [186, 413, 219, 447],\n","          [495, 209, 631, 343],\n","          [153, 100, 359, 368],\n","          [452, 279, 518, 318],\n","          [548, 252, 631, 340],\n","          [547, 279, 576, 348],\n","          [349, 289, 411, 392],\n","          [  0,   0, 194, 463],\n","          [285,  54, 564, 259],\n","          [297, 222, 606, 414],\n","          [ 52, 325, 327, 479],\n","          [357, 359, 466, 386],\n","          [136,  10, 449, 350],\n","          [261, 383, 291, 408],\n","          [  1,  38, 282, 255],\n","          [100, 297, 610, 454],\n","          [ 95, 377, 183, 471],\n","          [544, 273, 604, 348],\n","          [173, 411, 219, 466],\n","          [ 67,  77, 640, 435]], dtype=torch.int32),\n","  'scores': tensor([0.9855, 0.9673, 0.9627, 0.8639, 0.7468, 0.6087, 0.5868, 0.5218, 0.4814,\n","          0.4657, 0.4002, 0.3883, 0.3743, 0.2454, 0.2125, 0.1820, 0.1622, 0.1581,\n","          0.1322, 0.1171, 0.1163, 0.0786, 0.0748, 0.0737, 0.0727, 0.0718, 0.0702,\n","          0.0695, 0.0654, 0.0552, 0.0531]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1,\n","          2, 1, 2, 2, 2, 2, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[382, 263, 604, 441],\n","          [394, 357, 633, 443],\n","          [490, 370, 638, 445],\n","          [555, 373, 637, 438],\n","          [380, 318, 562, 412]], dtype=torch.int32),\n","  'scores': tensor([0.9870, 0.8463, 0.4694, 0.4080, 0.0598]),\n","  'labels': tensor([2, 2, 2, 2, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[  5, 239, 161, 465],\n","          [ 94, 246, 450, 339],\n","          [  8, 244, 274, 414],\n","          [613, 258, 638, 280],\n","          [  9,  14, 612, 299],\n","          [246, 253, 439, 327],\n","          [242, 249, 328, 334],\n","          [147, 257, 339, 336],\n","          [124, 274, 248, 345],\n","          [  8, 238, 171, 458],\n","          [  0, 359, 157, 467],\n","          [357, 289, 452, 312],\n","          [366, 295, 394, 313],\n","          [ 15, 240, 344, 424],\n","          [  1, 247, 511, 432],\n","          [302, 274, 467, 316]], dtype=torch.int32),\n","  'scores': tensor([0.9036, 0.7964, 0.4693, 0.3940, 0.3133, 0.2245, 0.2133, 0.2093, 0.2018,\n","          0.1830, 0.1460, 0.1286, 0.1157, 0.0924, 0.0772, 0.0638]),\n","  'labels': tensor([2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[ 54, 386, 146, 429],\n","          [ 45, 377, 224, 430],\n","          [ 49, 333, 256, 431],\n","          [ 52, 236, 636, 460],\n","          [ 53, 323, 259, 428]], dtype=torch.int32),\n","  'scores': tensor([0.9747, 0.8078, 0.0845, 0.0623, 0.0556]),\n","  'labels': tensor([2, 2, 2, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[150, 185, 207, 237],\n","          [275, 300, 319, 352],\n","          [ 40, 188,  76, 221],\n","          [237, 307, 425, 464],\n","          [195,  37, 623, 383],\n","          [273, 293, 303, 337],\n","          [246, 303, 321, 363]], dtype=torch.int32),\n","  'scores': tensor([0.8665, 0.6480, 0.3727, 0.1701, 0.1240, 0.1033, 0.0910]),\n","  'labels': tensor([2, 2, 2, 2, 1, 2, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[307, 104, 397, 328],\n","          [173,   8, 515, 304],\n","          [288, 246, 352, 326],\n","          [460, 303, 635, 475],\n","          [166,   8, 320, 251],\n","          [287,  86, 463, 371],\n","          [339,  80, 397, 227],\n","          [289,  52, 480, 366],\n","          [289, 183, 377, 327],\n","          [373,  85, 396, 120],\n","          [ 12,   6, 291, 243],\n","          [246,   0, 589, 156],\n","          [ 68,   0, 499, 197],\n","          [225, 120, 397, 326],\n","          [ 53, 108, 288, 243]], dtype=torch.int32),\n","  'scores': tensor([0.9068, 0.6903, 0.6781, 0.4382, 0.4037, 0.3771, 0.3387, 0.2465, 0.2246,\n","          0.2093, 0.2019, 0.1672, 0.1339, 0.0758, 0.0743]),\n","  'labels': tensor([2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[ 85, 242, 157, 293],\n","          [  1, 308,  25, 332],\n","          [368, 236, 438, 253],\n","          [ 73, 250, 209, 294],\n","          [  1, 305,  40, 334],\n","          [ 22, 239, 229, 309],\n","          [468, 249, 587, 286],\n","          [ 43, 245, 163, 302],\n","          [420, 214, 628, 287],\n","          [  6, 309,  21, 327],\n","          [545, 264, 561, 286],\n","          [ 42, 390, 168, 425],\n","          [ 11, 171, 214, 298],\n","          [102, 396, 167, 425],\n","          [  4,  47, 640, 442],\n","          [105, 256, 160, 289],\n","          [121, 401, 141, 420]], dtype=torch.int32),\n","  'scores': tensor([0.9590, 0.8326, 0.4471, 0.3301, 0.3235, 0.2026, 0.1792, 0.1735, 0.1647,\n","          0.1277, 0.1207, 0.1021, 0.0994, 0.0821, 0.0664, 0.0598, 0.0591]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[585, 226, 633, 328],\n","          [ 97, 227, 241, 385],\n","          [ 94, 220, 502, 372],\n","          [241, 237, 455, 362],\n","          [301, 171, 525, 352],\n","          [353, 229, 458, 332],\n","          [588, 249, 618, 324],\n","          [464, 173, 484, 197],\n","          [  0,   8, 602, 254],\n","          [383, 143, 533, 322],\n","          [238, 261, 365, 359],\n","          [108, 271, 212, 378],\n","          [508, 268, 529, 294],\n","          [  4,  16, 296, 277],\n","          [165, 251, 400, 362],\n","          [ 63, 336, 107, 371],\n","          [499, 262, 531, 297],\n","          [117, 259, 270, 361],\n","          [430, 142, 505, 320],\n","          [  1,  35, 168, 297],\n","          [ 62, 223, 322, 398],\n","          [ 79, 337, 102, 368],\n","          [ 63, 301, 123, 376],\n","          [244, 260, 312, 351],\n","          [466, 253, 534, 314],\n","          [137,  27, 424, 231],\n","          [295, 256, 388, 363],\n","          [592, 237, 637, 299],\n","          [591, 262, 609, 320]], dtype=torch.int32),\n","  'scores': tensor([0.9686, 0.9519, 0.9081, 0.8596, 0.8378, 0.8278, 0.7821, 0.7319, 0.6761,\n","          0.6062, 0.4710, 0.3036, 0.2925, 0.2394, 0.2254, 0.1846, 0.1678, 0.1202,\n","          0.1013, 0.0979, 0.0946, 0.0895, 0.0787, 0.0768, 0.0759, 0.0740, 0.0696,\n","          0.0677, 0.0577]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n","          2, 1, 2, 2, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[388, 350, 459, 406],\n","          [ 94, 391, 117, 415],\n","          [620, 385, 640, 415],\n","          [ 61, 392, 120, 417],\n","          [460, 343, 484, 367],\n","          [319, 348, 459, 408],\n","          [ 24,  43, 622, 411],\n","          [386, 379, 458, 404],\n","          [ 19, 164, 567, 397],\n","          [158, 323, 467, 409],\n","          [ 19, 285, 486, 417]], dtype=torch.int32),\n","  'scores': tensor([0.9793, 0.9426, 0.8204, 0.2636, 0.1858, 0.1684, 0.1502, 0.1048, 0.0738,\n","          0.0717, 0.0568]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[  1, 287, 149, 435],\n","          [387, 156, 632, 291],\n","          [ 58, 197, 161, 279],\n","          [157,  83, 333, 364],\n","          [483, 163, 633, 271],\n","          [168, 128, 611, 353],\n","          [390, 143, 511, 301],\n","          [103, 108, 441, 372],\n","          [  0, 286,  79, 424],\n","          [ 61, 179, 216, 286],\n","          [ 72, 136, 328, 294],\n","          [ 81,  31, 107,  73],\n","          [214, 149, 347, 389],\n","          [147,  90, 341, 386],\n","          [396, 161, 468, 289],\n","          [143, 142, 211, 297],\n","          [  7, 190, 307, 417],\n","          [243, 230, 331, 384]], dtype=torch.int32),\n","  'scores': tensor([0.9593, 0.9554, 0.9192, 0.8951, 0.8911, 0.7871, 0.7738, 0.6980, 0.6538,\n","          0.4218, 0.2682, 0.1817, 0.1098, 0.0959, 0.0910, 0.0739, 0.0615, 0.0600]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[206, 321, 336, 363],\n","          [250, 324, 328, 356],\n","          [196, 310, 454, 362],\n","          [307, 310, 449, 352],\n","          [377, 320, 449, 350],\n","          [201, 343, 268, 366],\n","          [311, 319, 401, 351],\n","          [270, 325, 309, 354],\n","          [ 25,   9, 604, 316]], dtype=torch.int32),\n","  'scores': tensor([0.9372, 0.8893, 0.7746, 0.5678, 0.5510, 0.1731, 0.1089, 0.0661, 0.0637]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[329, 302, 521, 392],\n","          [540, 334, 617, 403],\n","          [179, 314, 209, 337],\n","          [  3,   1, 629, 347],\n","          [323, 308, 360, 335],\n","          [405,   1, 630, 367],\n","          [372, 333, 515, 390],\n","          [534,   9, 633, 380],\n","          [323, 308, 439, 383],\n","          [397, 290, 421, 313],\n","          [379, 319, 615, 401],\n","          [472, 338, 622, 401],\n","          [  9,  85, 417, 334],\n","          [ 31, 159,  63, 187],\n","          [ 21, 165, 519, 383],\n","          [ 23, 276, 582, 448],\n","          [ 54, 213, 260, 346]], dtype=torch.int32),\n","  'scores': tensor([0.9859, 0.9641, 0.7121, 0.4889, 0.4782, 0.4356, 0.2375, 0.2021, 0.1418,\n","          0.1302, 0.1254, 0.1165, 0.0704, 0.0643, 0.0619, 0.0584, 0.0541]),\n","  'labels': tensor([2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[  0, 189, 409, 339],\n","          [112, 266, 330, 336],\n","          [ 41, 227, 558, 377],\n","          [257, 267, 620, 388],\n","          [498, 288, 638, 332],\n","          [546, 306, 636, 326],\n","          [404, 283, 597, 406],\n","          [  0,  12, 548, 264],\n","          [ 97, 282, 116, 308],\n","          [  3, 209, 282, 319],\n","          [122, 224, 415, 361],\n","          [452, 289, 632, 374],\n","          [  0, 156, 131, 305],\n","          [412, 347, 507, 411],\n","          [ 28, 234,  52, 262],\n","          [  1, 221, 105, 294],\n","          [319, 338, 380, 369],\n","          [339, 344, 372, 368],\n","          [105, 281, 278, 324],\n","          [302, 323, 388, 370],\n","          [468, 371, 500, 390],\n","          [456, 296, 558, 390],\n","          [336, 340, 510, 396],\n","          [276, 317, 439, 372],\n","          [  0, 112, 554, 373],\n","          [  1, 144,  39, 288],\n","          [367, 218, 633, 402],\n","          [554, 311, 597, 323],\n","          [371, 258, 535, 410],\n","          [497, 217, 638, 342],\n","          [ 94, 281, 126, 314],\n","          [395, 261, 634, 353],\n","          [199, 285, 309, 342],\n","          [326,  22, 638, 278]], dtype=torch.int32),\n","  'scores': tensor([0.8627, 0.7473, 0.7268, 0.4370, 0.3862, 0.3746, 0.3725, 0.3688, 0.3379,\n","          0.3277, 0.3054, 0.2310, 0.2172, 0.2160, 0.1897, 0.1401, 0.1261, 0.1204,\n","          0.1166, 0.1114, 0.0947, 0.0922, 0.0778, 0.0709, 0.0691, 0.0684, 0.0669,\n","          0.0650, 0.0626, 0.0620, 0.0564, 0.0534, 0.0524, 0.0501]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","          1, 2, 2, 2, 2, 2, 2, 2, 2, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[302,  98, 532, 392],\n","          [143, 167, 345, 317],\n","          [311, 230, 523, 390],\n","          [310,  88, 558, 174],\n","          [363, 170, 529, 325],\n","          [156,   0, 378, 183],\n","          [162, 164, 503, 317],\n","          [155,   0, 603, 200],\n","          [153,  30, 565, 354],\n","          [147,  33, 337, 291],\n","          [174, 151, 537, 314],\n","          [301, 282, 450, 395],\n","          [406, 208, 521, 311],\n","          [350, 249, 534, 324],\n","          [287,  86, 550, 263],\n","          [311, 291, 392, 394],\n","          [371,  92, 558, 147],\n","          [311, 282, 528, 342],\n","          [304, 301, 502, 364],\n","          [159,  40, 577, 364],\n","          [349,  63, 584, 327],\n","          [  4, 169, 149, 208]], dtype=torch.int32),\n","  'scores': tensor([0.9383, 0.7809, 0.7806, 0.6676, 0.6260, 0.5730, 0.4556, 0.3686, 0.3651,\n","          0.3518, 0.3492, 0.3126, 0.2503, 0.1844, 0.1839, 0.1307, 0.1277, 0.1135,\n","          0.0731, 0.0712, 0.0680, 0.0532]),\n","  'labels': tensor([2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[288, 334, 569, 473],\n","          [  1, 223, 197, 424],\n","          [ 12, 220, 350, 433],\n","          [  2,  23, 204, 418],\n","          [293,  13, 629, 391],\n","          [538, 417, 625, 465],\n","          [383, 350, 553, 459],\n","          [  0,   4, 638, 418],\n","          [ 89, 213, 612, 446],\n","          [285, 202, 486, 373],\n","          [290, 363, 428, 475],\n","          [542, 420, 592, 459],\n","          [320, 168, 623, 419],\n","          [105, 213, 470, 379],\n","          [283, 256, 512, 460],\n","          [  0,   6, 337, 311],\n","          [291, 403, 396, 474],\n","          [455, 400, 629, 469],\n","          [489,   4, 636, 459],\n","          [470, 355, 548, 464],\n","          [123, 274, 353, 450],\n","          [171, 338, 344, 460],\n","          [223, 281, 343, 453],\n","          [281, 203, 620, 462]], dtype=torch.int32),\n","  'scores': tensor([0.9605, 0.9282, 0.8871, 0.8476, 0.7492, 0.7023, 0.6815, 0.6699, 0.5940,\n","          0.4413, 0.2947, 0.2852, 0.2476, 0.2109, 0.2031, 0.2016, 0.1419, 0.0989,\n","          0.0864, 0.0862, 0.0858, 0.0813, 0.0734, 0.0641]),\n","  'labels': tensor([2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[125,  57, 474, 419],\n","          [434, 237, 585, 391],\n","          [226, 319, 445, 413],\n","          [304,  96, 388, 156],\n","          [245, 327, 329, 410],\n","          [369, 157, 582, 404],\n","          [208, 146, 562, 416],\n","          [  0, 438,  24, 479],\n","          [  1,   0, 173, 245],\n","          [113, 173, 418, 388],\n","          [105, 185, 280, 426],\n","          [460, 295, 587, 395],\n","          [143,  31, 451, 229],\n","          [316, 233, 441, 409],\n","          [288,  98, 455, 395],\n","          [332, 338, 447, 408],\n","          [463, 251, 548, 385],\n","          [110, 279, 336, 421],\n","          [222, 125, 392, 405],\n","          [192,  84, 469, 295],\n","          [121, 281, 546, 420]], dtype=torch.int32),\n","  'scores': tensor([0.9565, 0.8654, 0.4751, 0.4170, 0.2971, 0.2945, 0.2884, 0.2521, 0.1966,\n","          0.1822, 0.1537, 0.1375, 0.1075, 0.1053, 0.1037, 0.0903, 0.0878, 0.0874,\n","          0.0800, 0.0748, 0.0579]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[200, 122, 459, 375],\n","          [481, 262, 640, 480],\n","          [486,  44, 637, 480],\n","          [442, 228, 493, 310],\n","          [221, 206, 490, 352],\n","          [371, 216, 494, 316],\n","          [  0, 226, 226, 472],\n","          [  2,  60, 217, 410],\n","          [204, 241, 418, 376],\n","          [188,  75, 548, 438],\n","          [ 71,  54, 468, 381],\n","          [199,  99, 333, 366],\n","          [  0,  13, 298, 253],\n","          [  7,   4, 552, 226],\n","          [304, 112, 637, 472],\n","          [ 74,  88, 442, 423],\n","          [309, 271, 409, 345],\n","          [133, 282, 640, 476],\n","          [ 49, 198, 504, 459],\n","          [237,  12, 625, 330]], dtype=torch.int32),\n","  'scores': tensor([0.9905, 0.9313, 0.8675, 0.8345, 0.6992, 0.6516, 0.5225, 0.3992, 0.3717,\n","          0.2043, 0.1525, 0.1525, 0.1102, 0.0703, 0.0643, 0.0608, 0.0575, 0.0521,\n","          0.0505, 0.0501]),\n","  'labels': tensor([2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[368, 220, 640, 436],\n","          [126,  11, 633, 415],\n","          [ 16, 184, 466, 421],\n","          [  4, 384, 304, 473],\n","          [  8,  21, 233, 395],\n","          [ 19, 294, 640, 459],\n","          [257, 137, 627, 381],\n","          [ 56,  11, 408, 394],\n","          [ 13, 354, 480, 473],\n","          [204,  50, 465, 388],\n","          [265, 379, 634, 462],\n","          [205, 204, 443, 372],\n","          [369, 394, 640, 443],\n","          [109, 214, 364, 408],\n","          [349, 338, 640, 438],\n","          [ 18, 236, 309, 469],\n","          [406,  36, 640, 430],\n","          [306,   0, 633, 320],\n","          [347, 314, 439, 380],\n","          [  0, 168, 188, 420],\n","          [235,   0, 510, 286],\n","          [  0,   6, 282, 234],\n","          [549,   5, 634, 423],\n","          [227,   0, 632, 133]], dtype=torch.int32),\n","  'scores': tensor([0.8954, 0.8927, 0.8926, 0.8147, 0.7591, 0.4416, 0.4385, 0.3919, 0.3868,\n","          0.3402, 0.3199, 0.3181, 0.2919, 0.2361, 0.1931, 0.1693, 0.1392, 0.1104,\n","          0.0922, 0.0690, 0.0626, 0.0591, 0.0556, 0.0500]),\n","  'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[130, 264, 242, 358],\n","          [  0, 219,  74, 281],\n","          [  0, 214, 234, 334],\n","          [422, 310, 622, 409],\n","          [  0,  85, 258, 257],\n","          [569, 372, 640, 436],\n","          [ 39,  42, 611, 337],\n","          [  0, 213, 166, 296],\n","          [312, 277, 628, 422],\n","          [105, 253, 623, 402],\n","          [166, 287, 240, 361],\n","          [ 99, 228, 261, 375],\n","          [423, 321, 599, 377],\n","          [502, 322, 639, 437],\n","          [  2, 195, 316, 372],\n","          [  0, 220,  43, 270],\n","          [122, 252, 211, 328],\n","          [310, 324, 504, 369],\n","          [404, 326, 490, 348],\n","          [250, 309, 536, 379],\n","          [233, 135, 560, 316],\n","          [495, 321, 590, 396],\n","          [121, 258, 384, 380],\n","          [349, 326, 532, 355],\n","          [567, 376, 588, 400],\n","          [253, 335, 355, 394],\n","          [  1, 226,  26, 259],\n","          [165, 165, 625, 367],\n","          [129, 267, 187, 321],\n","          [ 11, 104, 424, 320],\n","          [239, 327, 431, 388],\n","          [ 57, 304, 619, 440],\n","          [414, 334, 478, 344],\n","          [209, 295, 383, 394],\n","          [227, 153, 371, 365],\n","          [319, 366, 348, 385]], dtype=torch.int32),\n","  'scores': tensor([0.9052, 0.8159, 0.7740, 0.7703, 0.7020, 0.6664, 0.5792, 0.5064, 0.4759,\n","          0.4382, 0.4336, 0.4275, 0.3941, 0.3904, 0.3116, 0.2562, 0.2371, 0.2252,\n","          0.2131, 0.2102, 0.1773, 0.1714, 0.1708, 0.1663, 0.1500, 0.1390, 0.1179,\n","          0.1128, 0.0887, 0.0886, 0.0848, 0.0769, 0.0742, 0.0724, 0.0553, 0.0507]),\n","  'labels': tensor([2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n","          2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[130, 260, 477, 452],\n","          [179,   4, 633, 417],\n","          [132, 102, 401, 455],\n","          [461, 384, 516, 449],\n","          [291, 385, 520, 452],\n","          [168, 342, 516, 454],\n","          [180,  92, 337, 292],\n","          [ 10,  88, 173, 278],\n","          [410, 386, 517, 450],\n","          [129, 221, 395, 373],\n","          [147,  70, 610, 450],\n","          [176, 173, 353, 339],\n","          [123, 313, 289, 444],\n","          [ 49,  14, 463, 374],\n","          [216, 305, 423, 453],\n","          [ 64,   0, 587, 225],\n","          [351,  95, 640, 437],\n","          [517, 366, 615, 439],\n","          [133, 326, 220, 444],\n","          [195,  99, 315, 212],\n","          [248, 358, 316, 445],\n","          [ 26,  43, 344, 303],\n","          [ 12,  34, 218, 366],\n","          [297, 396, 397, 452],\n","          [233, 279, 596, 454],\n","          [325,  29, 635, 307],\n","          [222, 252, 314, 333],\n","          [112, 106, 516, 451]], dtype=torch.int32),\n","  'scores': tensor([0.8997, 0.8129, 0.7496, 0.7479, 0.7329, 0.7204, 0.5656, 0.5254, 0.3835,\n","          0.3709, 0.3581, 0.3381, 0.3371, 0.3207, 0.2985, 0.2921, 0.2811, 0.1837,\n","          0.1449, 0.1085, 0.1070, 0.0951, 0.0897, 0.0845, 0.0710, 0.0689, 0.0653,\n","          0.0569]),\n","  'labels': tensor([2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2,\n","          2, 1, 2, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[189, 451, 262, 471],\n","          [245, 286, 398, 365],\n","          [  0, 336, 321, 379],\n","          [ 54,  44, 634, 347],\n","          [356, 127, 640, 329],\n","          [  3,  18, 377, 351],\n","          [240, 282, 530, 356],\n","          [ 20, 335, 281, 379],\n","          [ 21, 287, 479, 378],\n","          [238, 172, 626, 356],\n","          [272,  13, 621, 283],\n","          [ 26, 238, 378, 367],\n","          [353, 140, 640, 325],\n","          [238, 352, 269, 369],\n","          [262, 265, 571, 353],\n","          [ 11, 183, 232, 369],\n","          [ 18, 309, 363, 373],\n","          [132, 308, 472, 368],\n","          [235, 190, 616, 358],\n","          [ 40, 268, 619, 380],\n","          [  2, 345, 194, 381],\n","          [195,  18, 511, 335]], dtype=torch.int32),\n","  'scores': tensor([0.8386, 0.7714, 0.6255, 0.6158, 0.4510, 0.3978, 0.3085, 0.2784, 0.2649,\n","          0.1688, 0.1529, 0.1390, 0.1175, 0.0918, 0.0879, 0.0824, 0.0657, 0.0655,\n","          0.0613, 0.0610, 0.0547, 0.0523]),\n","  'labels': tensor([2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[ 14, 282, 442, 398],\n","          [505, 304, 636, 388],\n","          [268, 205, 441, 376],\n","          [565, 314, 638, 389],\n","          [  4, 315, 272, 403],\n","          [371, 222, 445, 341],\n","          [ 98, 204, 448, 393],\n","          [197, 282, 430, 382],\n","          [233, 176, 593, 390],\n","          [483, 216, 634, 387],\n","          [  6,   5, 302, 340],\n","          [  0,   0, 640, 306],\n","          [  0, 318,  52, 404],\n","          [  0, 322, 145, 407],\n","          [289, 176, 424, 310],\n","          [202, 323, 392, 378],\n","          [  0, 316,  27, 393],\n","          [286, 185, 510, 343],\n","          [338, 179, 443, 363],\n","          [306, 255, 442, 359],\n","          [236,   4, 614, 248],\n","          [170, 286, 283, 395],\n","          [100, 320, 246, 400],\n","          [ 13, 101, 474, 397],\n","          [475,  10, 636, 393],\n","          [ 10,  21, 165, 365]], dtype=torch.int32),\n","  'scores': tensor([0.9387, 0.9298, 0.9008, 0.8578, 0.7507, 0.6555, 0.6414, 0.5511, 0.2790,\n","          0.2693, 0.2461, 0.1926, 0.1304, 0.1260, 0.1193, 0.1000, 0.0892, 0.0844,\n","          0.0817, 0.0750, 0.0635, 0.0576, 0.0542, 0.0539, 0.0523, 0.0515]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1,\n","          1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[123, 309, 567, 464],\n","          [542, 243, 630, 334],\n","          [561, 267, 620, 333],\n","          [121, 304, 405, 425],\n","          [ 53, 248, 182, 380],\n","          [ 56, 247, 131, 361],\n","          [ 46, 255, 357, 405],\n","          [122, 308, 304, 396],\n","          [126, 317, 182, 383],\n","          [291, 325, 613, 477],\n","          [  5,  18, 493, 353],\n","          [125, 303, 230, 385],\n","          [209, 327, 448, 451],\n","          [ 87, 267, 255, 398],\n","          [532, 218, 584, 334],\n","          [ 83, 320, 112, 357],\n","          [  0, 254,  20, 271],\n","          [ 70, 272, 115, 361]], dtype=torch.int32),\n","  'scores': tensor([0.9355, 0.9228, 0.8604, 0.7462, 0.7400, 0.5967, 0.5601, 0.4194, 0.3569,\n","          0.3411, 0.3170, 0.2324, 0.1651, 0.1130, 0.0924, 0.0851, 0.0783, 0.0744]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[481, 216, 548, 337],\n","          [ 48, 314, 119, 377],\n","          [ 78, 330, 116, 376],\n","          [138, 381, 216, 462],\n","          [ 10,   2, 613, 318],\n","          [  6,  31, 348, 351],\n","          [230,   0, 619, 249],\n","          [ 85, 346, 114, 373],\n","          [128, 372, 380, 459],\n","          [120,   9, 460, 396],\n","          [ 11, 309, 121, 392],\n","          [129, 176, 390, 393],\n","          [  3,   6, 157, 370],\n","          [326,  16, 601, 375],\n","          [130, 366, 401, 466],\n","          [  4,   3, 279, 241],\n","          [180, 377, 211, 459],\n","          [ 66, 138, 582, 433],\n","          [437, 207, 562, 370],\n","          [111,  37, 287, 346]], dtype=torch.int32),\n","  'scores': tensor([0.9929, 0.9383, 0.9127, 0.8539, 0.8456, 0.4794, 0.3746, 0.3332, 0.3243,\n","          0.3175, 0.2111, 0.2005, 0.1720, 0.1008, 0.0918, 0.0891, 0.0603, 0.0594,\n","          0.0561, 0.0528]),\n","  'labels': tensor([2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[206, 314, 512, 433],\n","          [338,  87, 433, 344],\n","          [ 97, 352, 622, 460],\n","          [  3,  16, 259, 390],\n","          [149, 379, 207, 414],\n","          [591, 363, 638, 458],\n","          [ 14,  15, 509, 404],\n","          [  0, 213, 263, 404],\n","          [169,   5, 453, 253],\n","          [226, 323, 294, 413],\n","          [294, 339, 542, 465],\n","          [ 65, 372, 218, 415],\n","          [403, 363, 554, 473],\n","          [193,   2, 614, 357],\n","          [ 19, 228, 435, 451],\n","          [215, 356, 479, 423],\n","          [222, 317, 401, 419],\n","          [483, 361, 636, 479],\n","          [223, 229, 479, 452],\n","          [492,  12, 638, 202],\n","          [284, 111, 426, 399],\n","          [325, 337, 460, 433],\n","          [  8,   2, 372, 252],\n","          [197,  66, 505, 433],\n","          [ 39, 354, 416, 426],\n","          [ 88, 292, 462, 421],\n","          [ 31, 406, 520, 478],\n","          [571,  49, 639, 198],\n","          [104,   0, 594, 184],\n","          [245,  12, 426, 188],\n","          [461,   8, 640, 464],\n","          [105, 130, 540, 461],\n","          [331, 354, 417, 429],\n","          [256,  61, 435, 266],\n","          [ 43, 167, 533, 442],\n","          [374, 100, 424, 339],\n","          [ 44, 395, 500, 471],\n","          [129, 278, 567, 436],\n","          [167, 332, 308, 421],\n","          [335, 367, 528, 444],\n","          [  6, 358, 255, 472],\n","          [414, 224, 630, 399],\n","          [ 43, 346, 583, 462],\n","          [  1,  36, 140, 410],\n","          [338, 389, 623, 475],\n","          [199, 249, 437, 418],\n","          [154, 387, 198, 410],\n","          [457, 383, 573, 473]], dtype=torch.int32),\n","  'scores': tensor([0.9116, 0.8485, 0.8424, 0.8384, 0.8346, 0.8183, 0.7862, 0.7126, 0.6685,\n","          0.5193, 0.4654, 0.3487, 0.3430, 0.3414, 0.3149, 0.3080, 0.3059, 0.2805,\n","          0.2605, 0.2235, 0.2111, 0.1439, 0.1371, 0.1348, 0.1317, 0.1293, 0.1243,\n","          0.1196, 0.1185, 0.0973, 0.0955, 0.0950, 0.0809, 0.0800, 0.0788, 0.0780,\n","          0.0765, 0.0743, 0.0718, 0.0699, 0.0672, 0.0630, 0.0610, 0.0594, 0.0559,\n","          0.0555, 0.0522, 0.0517]),\n","  'labels': tensor([2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2,\n","          2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2],\n","         dtype=torch.int32)},\n"," {'boxes': tensor([[ 30, 122, 426, 313],\n","          [275, 415, 313, 456],\n","          [497, 435, 521, 457],\n","          [ 30,  35, 598, 316],\n","          [287, 416, 310, 451],\n","          [266, 287, 478, 463],\n","          [ 32, 124, 560, 435],\n","          [494, 379, 521, 456],\n","          [  4, 332,  46, 387],\n","          [272, 362, 522, 458],\n","          [274,  82, 632, 341],\n","          [263, 255, 472, 450],\n","          [126, 293, 532, 447],\n","          [349, 154, 622, 323],\n","          [274, 382, 332, 462],\n","          [244, 172, 606, 457],\n","          [276, 375, 385, 458],\n","          [ 13,  76, 283, 363],\n","          [179, 134, 478, 295],\n","          [304, 374, 438, 445],\n","          [612, 354, 637, 414],\n","          [337,  41, 634, 260],\n","          [ 24, 178, 291, 326],\n","          [162, 289, 352, 426],\n","          [101, 138, 361, 429],\n","          [541, 357, 559, 437],\n","          [268, 406, 444, 456]], dtype=torch.int32),\n","  'scores': tensor([0.9439, 0.9367, 0.6965, 0.6383, 0.5877, 0.5406, 0.4954, 0.4437, 0.3391,\n","          0.3068, 0.2562, 0.1852, 0.1720, 0.1609, 0.1583, 0.1575, 0.1518, 0.1406,\n","          0.1389, 0.1305, 0.1291, 0.1255, 0.1203, 0.0853, 0.0608, 0.0606, 0.0515]),\n","  'labels': tensor([1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2,\n","          1, 2, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[197, 228, 364, 392],\n","          [372,  87, 423, 108],\n","          [170, 231, 477, 412],\n","          [365, 244, 488, 410],\n","          [121, 344, 469, 403],\n","          [380, 332, 476, 408],\n","          [374,  93, 405, 108],\n","          [147, 143, 173, 227],\n","          [156, 283, 420, 390],\n","          [120, 362, 392, 392],\n","          [203, 260, 309, 376],\n","          [133, 155, 362, 393],\n","          [462, 188, 488, 400],\n","          [416, 189, 492, 416],\n","          [275, 273, 472, 411],\n","          [373, 196, 532, 434],\n","          [160, 378, 308, 415],\n","          [258, 160, 353, 407],\n","          [127, 372, 402, 403],\n","          [ 80,   2, 521, 199],\n","          [209, 293, 356, 382],\n","          [277, 228, 346, 379],\n","          [263, 298, 379, 392],\n","          [225, 183, 555, 439],\n","          [ 51, 121, 526, 408],\n","          [371,  82, 422, 132],\n","          [162, 343, 377, 388]], dtype=torch.int32),\n","  'scores': tensor([0.9177, 0.8921, 0.8822, 0.8605, 0.6283, 0.6147, 0.4720, 0.4391, 0.4286,\n","          0.2825, 0.2319, 0.2266, 0.1515, 0.1494, 0.1093, 0.1083, 0.1051, 0.1048,\n","          0.0988, 0.0975, 0.0854, 0.0696, 0.0687, 0.0659, 0.0613, 0.0588, 0.0512]),\n","  'labels': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n","          2, 2, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[502, 309, 618, 396],\n","          [271, 193, 395, 410],\n","          [ 11, 249, 173, 437],\n","          [431, 133, 459, 193],\n","          [ 70, 336, 164, 429],\n","          [448,   2, 636, 334],\n","          [ 13, 231, 103, 361],\n","          [  0,   2, 239, 281],\n","          [  3, 255, 349, 428],\n","          [281, 189, 348, 252],\n","          [407, 126, 462, 202],\n","          [ 36, 311, 225, 429],\n","          [500, 343, 602, 390],\n","          [285,   0, 634, 277],\n","          [  9,   0, 253, 122],\n","          [ 49, 360, 206, 426],\n","          [278, 189, 352, 374],\n","          [  0,  31, 177, 414],\n","          [557, 312, 617, 389],\n","          [  0,   0, 640, 327],\n","          [  7, 194, 137, 397],\n","          [  0,   0, 365, 193],\n","          [ 30,   0, 607, 100],\n","          [ 17, 102, 192, 304],\n","          [390, 192, 410, 210],\n","          [ 15, 283, 107, 427],\n","          [ 98,   0, 256, 195],\n","          [  1, 190, 224, 439]], dtype=torch.int32),\n","  'scores': tensor([0.9839, 0.9678, 0.9386, 0.9359, 0.6480, 0.5686, 0.5251, 0.4544, 0.4333,\n","          0.3846, 0.2897, 0.2631, 0.2303, 0.1825, 0.1439, 0.1224, 0.1224, 0.1204,\n","          0.1031, 0.0956, 0.0930, 0.0731, 0.0685, 0.0652, 0.0649, 0.0615, 0.0601,\n","          0.0595]),\n","  'labels': tensor([2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1,\n","          2, 2, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[218, 216, 477, 279],\n","          [ 84,  45, 576, 280],\n","          [271, 219, 454, 257],\n","          [225, 246, 329, 287],\n","          [166,  95, 465, 268],\n","          [ 17,  47, 508, 417],\n","          [ 11,  30, 332, 313],\n","          [334, 225, 456, 254],\n","          [191, 137, 483, 269],\n","          [  0,  73, 211, 408],\n","          [227, 225, 388, 286],\n","          [140,  50, 316, 271],\n","          [257,  52, 421, 267]], dtype=torch.int32),\n","  'scores': tensor([0.9061, 0.7518, 0.6129, 0.4338, 0.3648, 0.3055, 0.2789, 0.1467, 0.1199,\n","          0.1174, 0.0988, 0.0638, 0.0599]),\n","  'labels': tensor([2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1], dtype=torch.int32)},\n"," {'boxes': tensor([[137, 226, 617, 442],\n","          [508, 226, 640, 441],\n","          [401, 262, 640, 443],\n","          [ 12,   0, 610, 259],\n","          [195, 214, 457, 428],\n","          [ 15, 264, 231, 420],\n","          [ 46, 273, 379, 430],\n","          [564, 234, 638, 425],\n","          [  4,   9, 286, 304],\n","          [  5, 313, 111, 416],\n","          [ 73, 342, 218, 424],\n","          [292,   4, 628, 272],\n","          [  0,  36, 164, 296],\n","          [  0,  85, 381, 263],\n","          [387, 162, 570, 304],\n","          [ 32,  74, 616, 389],\n","          [523, 215, 635, 333]], dtype=torch.int32),\n","  'scores': tensor([0.9591, 0.8195, 0.4335, 0.4293, 0.3997, 0.3524, 0.3155, 0.2209, 0.1623,\n","          0.1131, 0.1128, 0.0997, 0.0889, 0.0830, 0.0705, 0.0628, 0.0539]),\n","  'labels': tensor([2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2], dtype=torch.int32)},\n"," {'boxes': tensor([[410, 218, 639, 476],\n","          [  7, 201, 268, 316],\n","          [167, 251, 357, 448],\n","          [318,   3, 638, 242],\n","          [215, 253, 335, 390],\n","          [257,  27, 640, 443],\n","          [321, 347, 634, 480],\n","          [385,  86, 636, 253],\n","          [116, 176, 571, 479],\n","          [431, 302, 598, 480],\n","          [  9, 161, 380, 327],\n","          [200, 200, 380, 412],\n","          [141, 176, 401, 470],\n","          [143, 245, 393, 475],\n","          [130, 398, 246, 476],\n","          [403, 134, 640, 369],\n","          [232, 164, 395, 356],\n","          [484, 105, 632, 239],\n","          [ 55, 130, 444, 430],\n","          [297, 368, 515, 478],\n","          [137, 369, 471, 480],\n","          [  8, 204, 252, 422],\n","          [125, 401, 258, 480],\n","          [268, 168, 399, 284],\n","          [  0, 226, 176, 321],\n","          [ 65, 173, 379, 326],\n","          [186, 322, 330, 403]], dtype=torch.int32),\n","  'scores': tensor([0.9358, 0.9110, 0.9057, 0.8824, 0.6639, 0.6375, 0.5822, 0.5655, 0.5348,\n","          0.5298, 0.5061, 0.4361, 0.4102, 0.3212, 0.3098, 0.2828, 0.2358, 0.2001,\n","          0.1990, 0.1347, 0.1088, 0.0823, 0.0775, 0.0749, 0.0605, 0.0536, 0.0518]),\n","  'labels': tensor([1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2,\n","          1, 2, 2], dtype=torch.int32)}]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":[],"metadata":{"id":"PT806pQ1rzgK"},"execution_count":null,"outputs":[]}]}