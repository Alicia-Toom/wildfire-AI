{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5953c005b024cf2a13d7e958d70157d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fcbcb815a0240ce81932a41de62d761",
              "IPY_MODEL_f782645cb35d44eeb9d2f45b1aad81e0",
              "IPY_MODEL_3e1e3ca174ba449bb7db25253187d9d9"
            ],
            "layout": "IPY_MODEL_30daabfbd44944aa9668d3ffee92a366"
          }
        },
        "6fcbcb815a0240ce81932a41de62d761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde6564d749646bab9e29641aa4d46f6",
            "placeholder": "​",
            "style": "IPY_MODEL_93827112944544c4a00583dc6db8790e",
            "value": "100%"
          }
        },
        "f782645cb35d44eeb9d2f45b1aad81e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f92313782bc471ba1600a54f50e3ef5",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41ebcb7f1aa9499c8a70802e05e95814",
            "value": 102530333
          }
        },
        "3e1e3ca174ba449bb7db25253187d9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c4a69c90c8e44be920713bcde621f4d",
            "placeholder": "​",
            "style": "IPY_MODEL_e3a4229adc8e423bbfbb9739467f034c",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 67.6MB/s]"
          }
        },
        "30daabfbd44944aa9668d3ffee92a366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde6564d749646bab9e29641aa4d46f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93827112944544c4a00583dc6db8790e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f92313782bc471ba1600a54f50e3ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ebcb7f1aa9499c8a70802e05e95814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c4a69c90c8e44be920713bcde621f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3a4229adc8e423bbfbb9739467f034c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Antonsen2/wildfire-ai/blob/research_2.0/optimization/notebooks/optimization_with_ray_object_detection_version2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYbIgO7K8uEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a58c4e-9891-4c7f-8c5f-b3ac7c771a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==0.4.6\n",
        "!pip install pycocotools\n",
        "!pip install torchvision\n",
        "!pip install ray"
      ],
      "metadata": {
        "id": "7hwbXulM8_qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d9c94a-9858-4b76-e9be-6182edee2704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations==0.4.6) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations==0.4.6) (1.7.3)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations==0.4.6) (6.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations==0.4.6) (4.6.0.66)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (3.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2023.1.23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.4)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65173 sha256=29bbe4a652288b10b89770f7ad9a395279ef30a0eb5f3ec3b73a6f6e78f372a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/e3/0b/99a239413035502833a7b07283894243fddf5ce3aa720ca8dd\n",
            "Successfully built albumentations\n",
            "Installing collected packages: albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.2.1\n",
            "    Uninstalling albumentations-1.2.1:\n",
            "      Successfully uninstalled albumentations-1.2.1\n",
            "Successfully installed albumentations-0.4.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (2.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pycocotools) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-2.2.0-cp38-cp38-manylinux2014_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.51.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from ray) (1.21.6)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray) (3.19.6)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray) (22.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray) (7.1.2)\n",
            "Collecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.18.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray) (3.9.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray) (2.25.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray) (2.6.2)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (5.10.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.12.0)\n",
            "Installing collected packages: distlib, virtualenv, ray\n",
            "Successfully installed distlib-0.3.6 ray-2.2.0 virtualenv-20.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj')"
      ],
      "metadata": {
        "id": "owpkJRD89CtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.8.2\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "metadata": {
        "id": "6xGS2f-T9Fp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78686923-699d-4179-8f40-7d2e95240dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 294157, done.\u001b[K\n",
            "remote: Counting objects: 100% (3949/3949), done.\u001b[K\n",
            "remote: Compressing objects: 100% (250/250), done.\u001b[K\n",
            "remote: Total 294157 (delta 3698), reused 3907 (delta 3689), pack-reused 290208\u001b[K\n",
            "Receiving objects: 100% (294157/294157), 590.93 MiB | 14.02 MiB/s, done.\n",
            "Resolving deltas: 100% (269634/269634), done.\n",
            "Note: switching to 'v0.8.2'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 2f40a483d7 [v0.8.X] .circleci: Add Python 3.9 to CI (#3063)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision.transforms as transform\n",
        "import albumentations as A\n",
        "import torchvision\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "from functools import partial\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from engine import train_one_epoch, evaluate\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import Any\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ],
      "metadata": {
        "id": "LSUVFqBr9Jv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)"
      ],
      "metadata": {
        "id": "K0_JASxnASq6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "e5953c005b024cf2a13d7e958d70157d",
            "6fcbcb815a0240ce81932a41de62d761",
            "f782645cb35d44eeb9d2f45b1aad81e0",
            "3e1e3ca174ba449bb7db25253187d9d9",
            "30daabfbd44944aa9668d3ffee92a366",
            "cde6564d749646bab9e29641aa4d46f6",
            "93827112944544c4a00583dc6db8790e",
            "1f92313782bc471ba1600a54f50e3ef5",
            "41ebcb7f1aa9499c8a70802e05e95814",
            "0c4a69c90c8e44be920713bcde621f4d",
            "e3a4229adc8e423bbfbb9739467f034c"
          ]
        },
        "outputId": "b5aa2f9a-1675-4321-e91c-6d8a528f7113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5953c005b024cf2a13d7e958d70157d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/train_annotations.csv')\n",
        "valid_df = pd.read_csv('/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/valid_annotations.csv')\n",
        "\n",
        "train_images = '/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/train'\n",
        "valid_images = '/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/valid'\n",
        "\n",
        "train_df.tail()"
      ],
      "metadata": {
        "id": "uly4JwRm9SFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "25123031-9c68-48a0-ce67-86a5a79a4f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        filename  width  height class  xmin  ymin  xmax  ymax\n",
              "1200  fire-9.jpg    640     480  fire    65   306   208   355\n",
              "1201  fire-9.jpg    640     480  fire     1   350    89   377\n",
              "1202  fire-9.jpg    640     480  fire   496   363   527   386\n",
              "1203  fire-9.jpg    640     480  fire   459   342   486   371\n",
              "1204  fire-9.jpg    640     480  fire   612   332   640   353"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6957a623-c12e-4c1f-bf91-9dd39042f0c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1200</th>\n",
              "      <td>fire-9.jpg</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>fire</td>\n",
              "      <td>65</td>\n",
              "      <td>306</td>\n",
              "      <td>208</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1201</th>\n",
              "      <td>fire-9.jpg</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>fire</td>\n",
              "      <td>1</td>\n",
              "      <td>350</td>\n",
              "      <td>89</td>\n",
              "      <td>377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1202</th>\n",
              "      <td>fire-9.jpg</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>fire</td>\n",
              "      <td>496</td>\n",
              "      <td>363</td>\n",
              "      <td>527</td>\n",
              "      <td>386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1203</th>\n",
              "      <td>fire-9.jpg</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>fire</td>\n",
              "      <td>459</td>\n",
              "      <td>342</td>\n",
              "      <td>486</td>\n",
              "      <td>371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1204</th>\n",
              "      <td>fire-9.jpg</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>fire</td>\n",
              "      <td>612</td>\n",
              "      <td>332</td>\n",
              "      <td>640</td>\n",
              "      <td>353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6957a623-c12e-4c1f-bf91-9dd39042f0c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6957a623-c12e-4c1f-bf91-9dd39042f0c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6957a623-c12e-4c1f-bf91-9dd39042f0c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPU = True\n",
        "DEVICE = torch.device('cuda') if GPU else torch.device('cpu')\n",
        "\n",
        "LABELS = train_df['class'].unique()\n",
        "NUM_OF_CLASSES = len(LABELS)+1\n",
        "IN_FEATURES = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "SAVE_PATH = '/content/drive/MyDrive/Skola/py-AI/wildfire/test_obj/models/'\n",
        "MODEL_NAME = 'model_include_fire.pt'"
      ],
      "metadata": {
        "id": "N5WCubPG9PVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch: tuple) -> tuple:\n",
        "  return tuple(zip(*batch))\n",
        "\n",
        "def train(config, model, train_loader, valid_loader) -> None:\n",
        "  params = [param for param in model.parameters() if param.requires_grad]\n",
        "  #optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)  # TODO: Optimize params\n",
        "  optimizer = torch.optim.SGD(params, lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "  #lr_schedule = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)  # TODO: Optimize params\n",
        "  lr_schedule = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config[\"step_size\"], gamma=config[\"gamma\"])\n",
        "\n",
        "  for epoch in range(config[\"epoch\"]):\n",
        "    train_one_epoch(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        data_loader=train_loader,\n",
        "        device=DEVICE,\n",
        "        epoch=epoch,\n",
        "        print_freq=len(train_loader)\n",
        "    )\n",
        "    \n",
        "    lr_schedule.step()\n",
        "    evaluate(\n",
        "        model=model,\n",
        "        data_loader=valid_loader,\n",
        "        device=DEVICE\n",
        "    )"
      ],
      "metadata": {
        "id": "LcpzPv-o-McD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images, targets) -> None:\n",
        "  max_images = 4\n",
        "  img_counter = 0\n",
        "\n",
        "  for image, target in zip(images, targets):\n",
        "    if img_counter == max_images:\n",
        "      break\n",
        "\n",
        "    img_counter += 1\n",
        "\n",
        "    sample = image.permute(1,2,0).cpu().numpy()\n",
        "    boxes = target['boxes'].cpu().numpy().astype(np.int32)\n",
        "    labels = target['labels'].cpu().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10,8))\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "      cv2.rectangle(\n",
        "          img=sample,\n",
        "          pt1=(box[0], box[1]),\n",
        "          pt2=(box[2], box[3]),\n",
        "          color=(1,0,0),\n",
        "          thickness=1\n",
        "      )\n",
        "      cv2.putText(\n",
        "          img=sample,\n",
        "          text=labels[i],\n",
        "          org=(box[0], box[1]-10),\n",
        "          fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
        "          fontScale=0.3,\n",
        "          color=(0,0,0),\n",
        "          thickness=1\n",
        "      )\n",
        "    \n",
        "    ax.set_axis_off();\n",
        "    ax.imshow((sample * 255).astype(np.uint8))"
      ],
      "metadata": {
        "id": "TcKFoX7O_Vi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelMap:\n",
        "  def __init__(self, labels: list) -> None:\n",
        "    self._map = {c: i+1 for i, c in enumerate(labels)}\n",
        "    self.reversed_map = {i: c for i, c in enumerate(labels)}\n",
        "\n",
        "  def fit(self, df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
        "    df[col] = df[col].map(self._map)\n",
        "    return df"
      ],
      "metadata": {
        "id": "XI8mXToz9oaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WildfireDataset(Dataset):\n",
        "  def __init__(self, df: pd.DataFrame, img_path: str, labels: list, transforms: Any = None, **kwargs) -> None:\n",
        "    super().__init__(**kwargs)\n",
        "    self.df = df\n",
        "    self.img_path = img_path\n",
        "    self.labels = labels\n",
        "    self.images = self.df['filename'].unique()\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, i: int) -> tuple:\n",
        "    img_file = os.path.join(self.img_path, self.images[i])\n",
        "\n",
        "    img = cv2.imread(img_file)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(np.float32)\n",
        "    img = img/255.0\n",
        "\n",
        "    img_data = self.df.loc[self.df['filename'] == self.images[i]]\n",
        "\n",
        "    xmins = img_data['xmin'].values\n",
        "    ymins = img_data['ymin'].values\n",
        "    xmaxs = img_data['xmax'].values\n",
        "    ymaxs = img_data['ymax'].values\n",
        "\n",
        "    boxes = torch.as_tensor(np.stack([xmins, ymins, xmaxs, ymaxs], axis=1), dtype=torch.float32)\n",
        "    labels = torch.as_tensor(img_data['class'].values, dtype=torch.int64)\n",
        "    _id = torch.tensor([i])\n",
        "\n",
        "    areas = (boxes[:,3] - boxes[:,1]) * (boxes[:,2] - boxes[:,0])\n",
        "    areas = torch.as_tensor(areas, dtype=torch.float32)\n",
        "\n",
        "    iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
        "\n",
        "    target = dict()\n",
        "    target['boxes'] = boxes\n",
        "    target['labels'] = labels\n",
        "    target['image_id'] = _id\n",
        "    target['area'] = areas\n",
        "    target['iscrowd'] = iscrowd\n",
        "\n",
        "    if self.transforms:\n",
        "      transformed = self.transforms(image=img, bboxes=boxes, labels=labels)\n",
        "      img = transformed['image']\n",
        "      target['boxes'] = torch.as_tensor(transformed['bboxes'], dtype=torch.float32)\n",
        "    \n",
        "    return torch.as_tensor(img, dtype=torch.float32), target\n",
        "\n",
        "  def get_h_w(self, image: str) -> tuple:\n",
        "    \"\"\"Get height and width of image\"\"\"\n",
        "    img_data = self.df.loc[self.df['filename'] == image]\n",
        "    return img_data['width'].values[0], img_data['height'].values[0]"
      ],
      "metadata": {
        "id": "A8_nQhxz-BbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = LabelMap(LABELS)  # 1='smoke', 2='fire'\n",
        "\n",
        "train_df = label_map.fit(train_df, 'class')\n",
        "valid_df = label_map.fit(valid_df, 'class')\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "wJQ1UFgM9scA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c1b01364-9cb1-4349-a25d-d80919d0fbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            filename  width  height  class  \\\n",
              "0  ck0qd8gs6ko7j0721x25cv4o3_jpeg.rf.005f5707706e...    640     480      1   \n",
              "1  ck0t40rhdz68s0a46ekx049a6_jpeg.rf.00403179fe5f...    640     480      1   \n",
              "2  ck0m0ch9ugnna07940o8x989j_jpeg.rf.0101cdb46a16...    640     480      1   \n",
              "3  ck0rr6bfa9b3w0721aw5unwdy_jpeg.rf.00982c053d66...    640     480      1   \n",
              "4  ck0uk75x5ysls0721e5a9j891_jpeg.rf.00d7fd8503e1...    640     480      1   \n",
              "\n",
              "   xmin  ymin  xmax  ymax  \n",
              "0   125   190   177   286  \n",
              "1   326   207   494   249  \n",
              "2   308   166   582   257  \n",
              "3   241   204   310   244  \n",
              "4   523   208   619   288  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10d660d4-9c7f-4d18-a02c-f70ffec94120\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ck0qd8gs6ko7j0721x25cv4o3_jpeg.rf.005f5707706e...</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>190</td>\n",
              "      <td>177</td>\n",
              "      <td>286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ck0t40rhdz68s0a46ekx049a6_jpeg.rf.00403179fe5f...</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>1</td>\n",
              "      <td>326</td>\n",
              "      <td>207</td>\n",
              "      <td>494</td>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ck0m0ch9ugnna07940o8x989j_jpeg.rf.0101cdb46a16...</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>1</td>\n",
              "      <td>308</td>\n",
              "      <td>166</td>\n",
              "      <td>582</td>\n",
              "      <td>257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ck0rr6bfa9b3w0721aw5unwdy_jpeg.rf.00982c053d66...</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>1</td>\n",
              "      <td>241</td>\n",
              "      <td>204</td>\n",
              "      <td>310</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ck0uk75x5ysls0721e5a9j891_jpeg.rf.00d7fd8503e1...</td>\n",
              "      <td>640</td>\n",
              "      <td>480</td>\n",
              "      <td>1</td>\n",
              "      <td>523</td>\n",
              "      <td>208</td>\n",
              "      <td>619</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10d660d4-9c7f-4d18-a02c-f70ffec94120')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10d660d4-9c7f-4d18-a02c-f70ffec94120 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10d660d4-9c7f-4d18-a02c-f70ffec94120');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Optimize params\n",
        "train_transform = A.Compose(\n",
        "    [\n",
        "      A.HorizontalFlip(p=0.5),\n",
        "      A.RandomBrightnessContrast(p=0.2),\n",
        "      ToTensorV2(p=1)\n",
        "    ],\n",
        "    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'])\n",
        ")\n",
        "valid_transform = A.Compose(\n",
        "    [ToTensorV2(p=1)],\n",
        "    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'])\n",
        ")"
      ],
      "metadata": {
        "id": "LRwRM8sg-HHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = WildfireDataset(train_df, train_images, LABELS, train_transform)\n",
        "valid_dataset = WildfireDataset(valid_df, valid_images, LABELS, valid_transform)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "QvoNf4Me-X6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# images, targets = next(iter(train_dataloader))\n",
        "# plot_images(images, targets)"
      ],
      "metadata": {
        "id": "g9so1AUH-a_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(IN_FEATURES, NUM_OF_CLASSES)\n",
        "model = model.to(DEVICE) "
      ],
      "metadata": {
        "id": "n4sZkS0P-n5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "23ccd2a0-0bd1-4d56-e81f-70b1546f2831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-51b3e8eff37a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_predictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfaster_rcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastRCNNPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIN_FEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_OF_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.device(\"cuda\"))\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "Zj3BZxm8X3pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "search_space = {\n",
        "    \"lr\": tune.choice([0.005, 0.010]),\n",
        "    \"momentum\": tune.choice([0.9, 1.8]),\n",
        "    \"weight_decay\": tune.choice([0.0005, 0.0010]),\n",
        "    \"step_size\": tune.choice([3, 6]),\n",
        "    \"gamma\": tune.choice([0.1, 0.2]),\n",
        "    \"epoch\": tune.choice([10, 20])\n",
        "}\n",
        "\n",
        "scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=1,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "\n",
        "reporter = CLIReporter(\n",
        "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "\n",
        "result = tune.run(\n",
        "  # Will throw ValueError: The actor ImplicitFunc is too large (158 MiB > FUNCTION_SIZE_ERROR_THRESHOLD=95 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
        "  partial(train, model, train_dataloader, valid_dataloader),\n",
        "  # Which can be fixed with tune_with_parameters - see link below \n",
        "  # https://docs.ray.io/en/master/tune/api_docs/trainable.html#tune-with-parameters\n",
        "  # But this will instead throw RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n",
        "  # tune.with_parameters(train, model=model, train_dataloader=train_dataloader, valid_dataloader=valid_dataloader),\n",
        "  config=search_space,\n",
        "  num_samples=1,\n",
        "  scheduler=scheduler,\n",
        "  progress_reporter=reporter)\n",
        "\n",
        "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "print(\"Best trial config: {}\".format(best_trial.config))\n",
        "print(\"Best trial final validation loss: {}\".format(\n",
        "    best_trial.last_result[\"loss\"]))\n",
        "print(\"Best trial final validation accuracy: {}\".format(\n",
        "    best_trial.last_result[\"accuracy\"]))\n",
        "\n",
        "#tuner = tune.Tuner(\n",
        "#    tune.with_parameters(\n",
        "#        train, \n",
        "#        model=model, \n",
        "#        train_dataloader=train_dataloader, \n",
        "#        valid_dataloader=valid_dataloader),\n",
        "#    param_space=search_space)\n",
        "#results = tuner.fit()\n",
        "#print(results.get_best_result(metric=\"score\", mode=\"min\").config)\n",
        "\n",
        "#tuner = tune.Tuner(\n",
        "#    tune.with_resources(\n",
        "#          tune.with_parameters(train, model=model, train_dataloader=train_dataloader, valid_dataloader=valid_dataloader),\n",
        "#    {\"gpus\": 1, \"cpus\": 1}),\n",
        "#    param_space=search_space)\n",
        "#results = tuner.fit()\n",
        "#print(results.get_best_result(metric=\"score\", mode=\"min\").config)\n",
        "\n",
        "\n",
        "#train(model, train_dataloader, valid_dataloader, config)"
      ],
      "metadata": {
        "id": "h3igVuFh_ZKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), SAVE_PATH + MODEL_NAME)"
      ],
      "metadata": {
        "id": "jSb8RYKH_Zug"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}